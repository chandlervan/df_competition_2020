{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原始训练数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T14:22:54.389641Z",
     "start_time": "2020-03-03T14:22:28.514990Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import codecs\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T14:22:54.398460Z",
     "start_time": "2020-03-03T14:22:54.392594Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NLS_LANG'] = 'SIMPLIFIED CHINESE_CHINA.UTF8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T14:22:55.769431Z",
     "start_time": "2020-03-03T14:22:54.406872Z"
    }
   },
   "outputs": [],
   "source": [
    "with codecs.open('./dataset/nCoV_100k_train.labled.csv','rb',errors='ignore') as f:\n",
    "    train_data = []\n",
    "    for line in f.readlines():\n",
    "        try:\n",
    "            train_data.append(codecs.decode(line,'gbk',errors='ignore').strip('\\r\\n'))\n",
    "        except UnicodeDecodeError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T14:22:56.575165Z",
     "start_time": "2020-03-03T14:22:55.772452Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_train_data = [v.split(',[') for v in train_data]\n",
    "tmp_train_data = [v for v in tmp_train_data if len(v)<4]\n",
    "text = [[v[0].split(',')[0],''.join(v[0].split(',')[3:]),v[-1].split(',')[-1]] for v in tmp_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T14:22:56.913454Z",
     "start_time": "2020-03-03T14:22:56.577676Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(text[1:],columns=text[0])\n",
    "train_df.columns = ['微博id','微博内容','情感倾向']\n",
    "train_df['文本长度'] = train_df['微博内容'].map(len)\n",
    "train_df = train_df[train_df['情感倾向'].isin(['-1','0','1'])]\n",
    "label_map = {'-1':0,'0':1,'1':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T14:22:56.926066Z",
     "start_time": "2020-03-03T14:22:56.917991Z"
    }
   },
   "outputs": [],
   "source": [
    "label_map_reverse = {0:-1, 1:0, 2:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T14:22:57.151974Z",
     "start_time": "2020-03-03T14:22:56.929121Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['情感倾向'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原始测试数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('./dataset/nCov_10k_test.csv','rb',errors='ignore') as f:\n",
    "    test_data = []\n",
    "    for line in f.readlines():\n",
    "        test_data.append(codecs.decode(line,'gbk',errors='ignore').strip('\\r\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_test_data = [v.split(',[') for v in test_data]\n",
    "tmp_test_data = [v for v in tmp_test_data if len(v)<4]\n",
    "test_text = [[v[0].split(',')[0],''.join(v[0].split(',')[3:])] for v in tmp_test_data]\n",
    "test_df = pd.DataFrame(test_text,columns =['微博id','微博内容'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T09:35:56.058721Z",
     "start_time": "2020-03-01T09:35:56.049744Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import keras\n",
    "from bert4keras.tokenizer import Tokenizer\n",
    "from bert4keras.bert import build_bert_model\n",
    "from bert4keras.optimizers import Adam, extend_with_piecewise_linear_lr\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from keras.layers import Lambda, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T09:15:15.471129Z",
     "start_time": "2020-03-01T09:15:15.463151Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "maxlen = 300\n",
    "batch_size = 8\n",
    "config_path = './chinese_wwm_ext_L-12_H-768_A-12/bert_config.json'\n",
    "checkpoint_path = './chinese_wwm_ext_L-12_H-768_A-12/bert_model.ckpt'\n",
    "dict_path = './chinese_wwm_ext_L-12_H-768_A-12/vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T09:16:09.171569Z",
     "start_time": "2020-03-01T09:16:09.082771Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(dict_path,do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T09:22:03.208812Z",
     "start_time": "2020-03-01T09:22:03.190862Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class data_generator(DataGenerator):\n",
    "    \"\"\"数据生成器\n",
    "    \"\"\"\n",
    "    def __iter__(self, random=False):\n",
    "        idxs = list(range(len(self.data)))\n",
    "        if random:\n",
    "            np.random.shuffle(idxs)\n",
    "        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "        for i in idxs:\n",
    "            text, label = self.data[i]\n",
    "            token_ids, segment_ids = tokenizer.encode(text, max_length=maxlen)\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_segment_ids.append(segment_ids)\n",
    "            batch_labels.append([label])\n",
    "            if len(batch_token_ids) == self.batch_size or i == idxs[-1]:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                batch_labels = sequence_padding(batch_labels)\n",
    "                yield [batch_token_ids, batch_segment_ids], batch_labels\n",
    "                batch_token_ids, batch_segment_ids, batch_labels = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型测试数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_token_ids, test_segment_ids = [], []\n",
    "for i in range(len(test_df)):\n",
    "    text = test_df['微博内容'].values[i]\n",
    "    token_ids, segment_ids = tokenizer.encode(text, max_length=maxlen)\n",
    "    test_token_ids.append(token_ids)\n",
    "    test_segment_ids.append(segment_ids)\n",
    "test_token_ids = sequence_padding(test_token_ids)\n",
    "test_segment_ids = sequence_padding(test_segment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T09:35:14.539743Z",
     "start_time": "2020-03-01T09:35:08.221679Z"
    }
   },
   "outputs": [],
   "source": [
    "bert = build_bert_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    return_keras_model=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T09:35:27.227853Z",
     "start_time": "2020-03-01T09:35:27.167974Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = Lambda(lambda x: x[:, 0], name='CLS-token')(bert.model.output)\n",
    "output = Dense(units=num_classes,\n",
    "               activation='softmax',\n",
    "               kernel_initializer=bert.initializer)(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T09:35:59.151449Z",
     "start_time": "2020-03-01T09:35:59.120564Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Model(bert.model.input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T09:36:26.270187Z",
     "start_time": "2020-03-01T09:36:26.175188Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义模型的评价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaluator(keras.callbacks.Callback):\n",
    "    def __init(self):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        _y_pred = []\n",
    "        _y_true = []\n",
    "        for x, label in valid_generator:\n",
    "            y_pred = model.predict(x)\n",
    "            y_pred = [v.argmax() for v in y_pred]\n",
    "            y_true = [v[0] for v in label]\n",
    "            _y_pred.extend(y_pred)\n",
    "            _y_true.extend(y_true)\n",
    "        print(u'f1_score: %.5f\\n' % (f1_score(_y_true,_y_pred,average='macro')))\n",
    "_evaluator = evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 划分测试集训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(range(len(train_df)))\n",
    "np.random.shuffle(idx)\n",
    "train_idxs = idx[:int(0.9 * len(idx))]\n",
    "test_idxs = idx[int(0.9 * len(idx)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_df[['微博内容','label']].values[train_idxs]\n",
    "test_data = train_df[['微博内容','label']].values[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T09:37:14.373341Z",
     "start_time": "2020-03-01T09:37:14.349406Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(train_data, batch_size)\n",
    "valid_generator = data_generator(test_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T09:39:45.128171Z",
     "start_time": "2020-03-01T09:37:14.789226Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator.forfit(),\n",
    "                    steps_per_epoch=len(train_generator),\n",
    "                    epochs=2,\n",
    "                    callbacks=[_evaluator])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_res = model.predict([test_token_ids,test_segment_ids],batch_size=64)\n",
    "test_res_lable = [v.argmax() for v in test_res]\n",
    "test_df['label'] = test_res_lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('./dataset/submit_example.csv')\n",
    "sample.columns = ['微博id','y']\n",
    "sample['微博id'] = sample['微博id'].map(lambda x:str(x) + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = sample.merge(test_df[['微博id','label']],how='left',on='微博id')\n",
    "sample['label'] = sample['label'].fillna(1)\n",
    "sample['label'] = sample['label'].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample['label'] = sample['label'].map(label_map_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['微博id'] = sample['微博id'].map(lambda x:x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample[['微博id','label']].to_csv('submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
